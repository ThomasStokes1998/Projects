{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pneumonia Detection\n\nI am trying to build a CNN that can detect Pneumonia using the images. I am using this Kaggle notebook as a guide: https://www.kaggle.com/dpaluszk/pneumonia-transfer-learning-94-acc. This project is for me to learn how to make Image classification neural networks.","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"# Imports\n\n# Generic Imports\nimport os\nimport numpy as np \nimport pandas as pd \n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport PIL\n\n%matplotlib inline\n\n# Creating the CNN's\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Flatten, LeakyReLU, BatchNormalization, Dropout, Input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# File Paths\n\nbase_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/'\ntest_path = os.path.join(base_path,'test')\ntrain_path = os.path.join(base_path,'train')\nval_path = os.path.join(base_path, 'val')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualisation","metadata":{}},{"cell_type":"code","source":"def visualise_images(dir_path):\n        images = os.listdir(dir_path)\n        images = [img for img in images if img.endswith('jpeg')]\n        fig = plt.figure(figsize=(24,24))\n        for i in range(2):\n            for j in range(2):\n                img = np.random.choice(images)\n                img = PIL.Image.open(os.path.join(dir_path,img))\n                axobj = fig.add_subplot(2, 2, i * 2 + j + 1)\n                axobj.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualise_images(os.path.join(test_path, 'PNEUMONIA'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualise_images(os.path.join(test_path, 'NORMAL'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the Images\nThe images are different sizes. We will have to make all the images the same size for our model to work.","metadata":{}},{"cell_type":"code","source":"# Global Variables\nIMAGE_SIZE=(224,224)\nBATCH_SIZE=64\n\n# Resizes the training data\ntrain_datagen  = ImageDataGenerator(\n    rescale=1./255, # Ensures the values are between 0 and 1\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary')\n\n# Resizes the test data\ntest_datagen  = ImageDataGenerator(\n    rescale=1./255,\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Models\nWe are going to experiment with four models for image classification:\n* A 'simple' CNN with 4 convolution layers with different features (i.e. Batchnormalization, dropout)\n* Xception transfer learning\n* ResNet transfer learning\n* VGG16 transfer learning\n* Inception transfer learning\n* Densenet121 transfer learning","metadata":{}},{"cell_type":"markdown","source":"### Simple CNN\n\nHere we will create a customisable CNN. There are a lot of different features we can add to a CNN so it is worth experimenting with different features to see which one gives the best results.","metadata":{}},{"cell_type":"code","source":"def simple_model( activ, batchnorm=False, dropout=False):\n    if batchnorm:\n        if dropout:\n            simp = Sequential([\n                Input(shape=(224, 224, 3,)), Conv2D(64, 5, 2), LeakyReLU(), MaxPool2D(2), BatchNormalization(), Dropout(0.2),\n                Conv2D(128, 3, 2), LeakyReLU(), MaxPool2D(2), BatchNormalization(), Dropout(0.2),\n                Conv2D(256, 3, 1, padding='same'),  LeakyReLU(), MaxPool2D(2), BatchNormalization(), Dropout(0.2),\n                Conv2D(512, 3, 1, padding='same'),  LeakyReLU(), MaxPool2D(2), BatchNormalization(), Dropout(0.2),\n                Flatten(), Dense(128), LeakyReLU(), Dense(64), LeakyReLU(), Dense(1, activation=activ)])\n        if not dropout:\n            simp = Sequential([\n                Input(shape=(224, 224, 3,)), Conv2D(64, 5, 2), LeakyReLU(), MaxPool2D(2), BatchNormalization(),\n                Conv2D(128, 3, 2), LeakyReLU(), MaxPool2D(2), BatchNormalization(),\n                Conv2D(256, 3, 1, padding='same'),  LeakyReLU(), MaxPool2D(2), BatchNormalization(),\n                Conv2D(512, 3, 1, padding='same'),  LeakyReLU(), MaxPool2D(2), BatchNormalization(),\n                Flatten(), Dense(128), LeakyReLU(), Dense(64), LeakyReLU(), Dense(1, activation=activ)])\n    if not batchnorm:\n        if dropout:\n            simp = Sequential([\n                Input(shape=(224, 224, 3,)), Conv2D(64, 5, 2), LeakyReLU(), MaxPool2D(2), Dropout(0.2),\n                Conv2D(128, 3, 2), LeakyReLU(), MaxPool2D(2), Dropout(0.2),\n                Conv2D(256, 3, 1, padding='same'),  LeakyReLU(), MaxPool2D(2), Dropout(0.2),\n                Conv2D(512, 3, 1, padding='same'),  LeakyReLU(), MaxPool2D(2), Dropout(0.2),\n                Flatten(), Dense(128), LeakyReLU(), Dense(64), LeakyReLU(), Dense(1, activation=activ)])\n        if not dropout:\n            simp = Sequential([\n                Input(shape=(224, 224, 3,)), Conv2D(64, 5, 2), LeakyReLU(), MaxPool2D(2),\n                Conv2D(128, 3, 2), LeakyReLU(), MaxPool2D(2),\n                Conv2D(256, 3, 1, padding='same'),  LeakyReLU(), MaxPool2D(2),\n                Conv2D(512, 3, 1, padding='same'),  LeakyReLU(), MaxPool2D(2),\n                Flatten(), Dense(128), LeakyReLU(), Dense(64), LeakyReLU(), Dense(1, activation=activ)])\n    return simp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simp = simple_model('sigmoid')\nsimp.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\nsimp2 = simple_model('relu')\nsimp2.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\nsimp3 = simple_model('softmax')\nsimp3.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The other models\n\nTo speed things up we will define some functions that do most of the work for us since the code for these models is ver similar. ","metadata":{}},{"cell_type":"code","source":"# Get's the model to the point where it can be trained\ndef prepare_model(model, input_shape=(224, 224, 3), optimizer='adam'):\n    pre_model = model(input_shape=input_shape,\n                 include_top=False,\n                 weights='imagenet')\n    \n    for layer in pre_model.layers:\n        layer.trainable = False\n        \n    last_out = pre_model.layers[-1].output\n    x = Flatten()(last_out) \n    x = Dense(512, activation='relu')(x)\n    x = Dense(1, activation='sigmoid')(x)\n    \n    model = tf.keras.Model(pre_model.input, x)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')\n    \n    return model   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Trains the models\ndef train_model(model, name, train, test, epochs=5):\n    callbacks =[] \n    callbacks.append(tf.keras.callbacks.EarlyStopping(patience=5))\n    callbacks.append(tf.keras.callbacks.ModelCheckpoint(os.path.join('/kaggle/working/models', name), save_best_only=True))\n    \n    history = model.fit(train, validation_data=test, epochs=epochs, callbacks=callbacks)\n    \n    return model, name, history\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See this link for a list of pretrained models: https://keras.io/api/applications/","metadata":{}},{"cell_type":"code","source":"# Creating a list of models\nmodels_to_prepare = [\n    (tf.keras.applications.inception_v3.InceptionV3, 'inception'),\n    (tf.keras.applications.ResNet50, 'resnet'),\n    (tf.keras.applications.vgg16.VGG16, 'vgg'),\n    (tf.keras.applications.xception.Xception, 'xception'),\n    (tf.keras.applications.DenseNet121, 'densenet')\n]\n\nmodels = [(prepare_model(model[0]), model[1]) for model in models_to_prepare]\n\nmodels += [\n    (simp, 'simp'),\n    (simp2, 'simp2'),\n    (simp3, 'simp3')\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Trains the models\ntrained_models = []\nhistories = []\nfor model in models:\n    print(model[1])\n    if model[1] == 'vgg':\n        model, name, history = train_model(model[0], model[1], train_generator, test_generator, epochs=3)\n    else:\n        model, name, history = train_model(model[0], model[1], train_generator, test_generator, epochs=5)            \n    trained_models.append(model)\n    histories.append((name, history))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation Visualisation","metadata":{}},{"cell_type":"code","source":"def present_training_results(histories):\n    length = len(histories)\n    fig = plt.figure(figsize=(24, 4 * length))\n    for i, j in enumerate(histories):\n        name, history = j\n        history = history.history\n        for k, key in enumerate(history.keys()):\n            axobj = fig.add_subplot(length, 4, 4 * i + k + 1)\n            axobj.plot(history[key], label=(key + '_' + name))\n            axobj.legend()\n            if 'acc' in key:\n                axobj.set_ylim((0.5 ,1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"present_training_results(histories)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in histories:\n    name, history = j\n    history = history.history\n    print(name, max(history['val_accuracy']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the validation data\nval_datagen  = ImageDataGenerator(\n    rescale=1./255,\n)\n\nval_generator = test_datagen.flow_from_directory(\n    val_path,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluates a given model with the validation data\ndef evaluate_model(name, data):\n    model = tf.keras.models.load_model(os.path.join('/kaggle/working/models', name))\n    model.evaluate(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    nom = model[1]\n    print(nom)\n    evaluate_model(nom, val_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n**Inception** \\\nInception was very correct to train (3-4s per step) but it started overfitting very quickly (after only 2 epochs). However Inception did get a very high evaluation: $0.9375$. \\\n**ResNet** \\\nResnet was still quite fast to train (6-7s per step) and there wasn't any evidence of overfitting after 5 epochs. Despite this, ResNet got a very low evaluation: $0.6875$. \\\n**VGG16** \\\nVGG16 took a very long to train, so long in fact I only had it do three epochs. Despite that VGG16 performed very well and got an evaluation score of $0.9375$. \\\n**Xception** \\\nXception got up to its peak accuracy after only two epochs, but its validation accuracy for each epoch stayed roughly the same. Like Inception and VGG16, Xception got an evaluation score of $0.9375$. \\\n**DenseNet121** \\\nDensenet managed to correctly predict the entire validation dataset. It also managed to get a validation accuracy of 91% after only three epochs. It also trained reasonably quickly (7s per step). I think it is clear that DenseNet121 is the best all round model. \\\n**CNNs** \\\nI wanted to test the which was the best activator for the Sequential model: Sigmoid (Simp) or Relu (Simp2). Both models trained very quickly. Simp kept on improving throughout the 5 epochs and likely would have peaked alongside the other models. Simp2 on the otherhand plateaued pretty much immediately and didn't approve at all across the 5 epochs. This showed in the evaluation where Simp scored $0.8125$ which is noticably worse that the best three models. Simp2 score $0.5$ which means it was no better than randomly guessing. Softmax is clearly the better activation function.","metadata":{}}]}